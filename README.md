#P3 Behavior Cloning
The objective of this project is to clone the human's driving behavior using the car simulator and the convolutional neural network (CNN). To collect data to train the CNN, we use the simulator to record frame-by-frame images of the track and the corresponding steering angles input by the driver. A properly trained CNN is expected to use each frame as an input and predicts the steering angle as an output. As a result, the car in the simulator can continuously drive itself on the road without going off-track in the autonomous mode.

##Model Architecture
The color images from the dataset has the dimesion of 320x160 (WxH). After preprocessing, the image is resized to 220x60 (WxH). 220x60 is chosen based on Nvidia's paper [End to End Learning for Self-Driving Cars](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0ahUKEwjJ6sjqw__RAhXL64MKHa5NBd4QFggcMAA&url=https%3A%2F%2Fimages.nvidia.com%2Fcontent%2Ftegra%2Fautomotive%2Fimages%2F2016%2Fsolutions%2Fpdf%2Fend-to-end-dl-using-px.pdf&usg=AFQjCNGgCrFq0dg2NHSt-N0gi9ult70wig&sig2=C-E6D6aB57ozFW6uH0eYUw).  The first layer performs normalization so that each color channel has the value between -0.5 and 0.5. It is followed by 3 convolutional layers with 3x3 kernel. The output from the last convolutional layer is flattened, and fed to 3 fully connected layers. In between the convolutional layers, dropout layer is used to reduced overfitting and ReLU is used as the activation function. In between the fully conneted layers, ELU is used. [ELU](http://arxiv.org/pdf/1511.07289v1.pdf) has been shown to enable the network learn faster. The final output is the steering angle to control the car in the simulator.

## Training Strategy
The data is critical to the success of the training. Although training mode is available in the simulator to collect data, Udacity provides its data for the students as the starting point. The data was recorded by 3 cameras: left, center and right. At first, it is not immediately clear whether such data is sufficient to train the model. However, after converting the center image sequence to video and play it back, we learn that the data consists of balanced amount of data of the car driving in normal direction of the track and the opposite one.
